---
subtitle: "Factorial Data Example"
output:
  github_document:
    preserve_yaml: FALSE
vignette: >
  %\VignetteIndexEntry{Factorial Data Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 6, fig.path = "figures/", echo = TRUE, warning = FALSE, message = FALSE)
devtools::source_gist("8e6e5dc401e3fc1042ef7a030f9d19c7", filename = "revised_toc.R")
```

```{r, include=FALSE}
if (!require(EASI)) {
  if (!require(remotes)) install.packages("remotes")
  remotes::install_github("cwendorf/EASI")
}
library(EASI)
```

## Factorial Data Example

This page analyzes a two-factor between-subjects (factorial) design using raw data input.

```{r toc, echo=FALSE}
thisfile <- knitr::current_input()
revised_toc(thisfile, base_level = 3, toc_depth = 4)
```

---

### Data Management

#### Data Entry

This code inputs the variable names and creates a viewable data frame.
```{r}
FactorA <- c(rep(1, 20), rep(2, 20), rep(3, 20))
FactorA <- factor(FactorA, levels = c(1, 2, 3), labels = c("A1", "A2", "A3"))
FactorB <- c(rep(1, 10), rep(2, 10), rep(1, 10), rep(2, 10), rep(1, 10), rep(2, 10))
FactorB <- factor(FactorB, levels = c(1, 2), labels = c("B1", "B2"))
Outcome <- c(6, 8, 6, 8, 10, 8, 10, 9, 8, 7, 5, 9, 10, 9, 11, 4, 11, 7, 6, 8, 7, 13, 11, 10, 13, 8, 11, 14, 12, 11, 7, 8, 7, 11, 10, 7, 8, 4, 8, 10, 9, 16, 11, 12, 15, 13, 9, 14, 11, 10, 8, 6, 8, 11, 5, 7, 9, 3, 6, 7)
FactorialData <- construct(FactorA, FactorB, Outcome)
```

This code subsets the data into two different data frames (for simple effects analysis).
```{r}
FactorialDataB1 <- subset(FactorialData, FactorB == "B1")
FactorialDataB2 <- subset(FactorialData, FactorB == "B2")
```

#### Summary Statistics

This code obtains the descriptive statistics for the two data frames.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> describeSummary()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> describeSummary()
```

### Analyses of the Means

This section produces analyses that are equivalent to one-sample analyses separately for each level of a factor.

#### Confidence Intervals

This code will provide tables of confidence intervals for each level of the factor.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeans()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeans()
```

This code will produce a graph of the confidence intervals for each level of the factor.
```{r, Factorial-Data-MeansA}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeans()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeans()
```

The code defaults to 95% confidence intervals. This can be changed if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeans(conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeans(conf.level = .99)
```

For the graph, it is possible to add a comparison line to represent a population (or test) value and a region of practical equivalence in addition to changing the confidence level.
```{r, Factorial-Data-MeansB}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeans(conf.level = .99, line = 9, rope = c(8, 10))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeans(conf.level = .99, line = 9, rope = c(8, 10))
```

#### Significance Tests

This code will produce a table of NHST separately for each level of the factor. In this case, all the means are tested against a value of zero.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> testMeans()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> testMeans()
```

Often, the default test value of zero is not meaningful or plausible. This too can be altered (often in conjunction with what is presented in the plot).
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> testMeans(mu = 9)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> testMeans(mu = 9)
```

#### Standardized Effect Sizes

This code will produce a table of standardized mean differences separately for each level of the factor. In this case, the mean is compared to zero to form the effect size.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeans()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeans()
```

Here too it is possible to alter the width of the confidence intervals and to establish a more plausible comparison value for the mean.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeans(mu = 9, conf.level = .99)
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeans(mu = 9, conf.level = .99)
```

### Analyses of a Comparison

This section produces analyses involving comparisons of two levels of a factor.

#### Confidence Intervals

This code estimates the confidence interval of the difference.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanDifference()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanDifference()
```

This code obtains and plots the confidence intervals for the mean difference in the identified comparison.
```{r, Factorial-Data-DifferenceA}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanDifference()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanDifference()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanDifference(conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanDifference(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, Factorial-Data-DifferenceB}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanDifference(conf.level = .99, line = 0, rope = c(-2, 2))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanDifference(conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the means and the mean difference in one command.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanComparison()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanComparison()
```

This code produces a difference plot using the confidence intervals for the means and the mean difference.
```{r, Factorial-Data-ComparisonA}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanComparison()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanComparison()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanComparison(conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateMeanComparison(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, Factorial-Data-ComparisonB}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanComparison(conf.level = .99, rope = c(-2, 2))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> plotMeanComparison(conf.level = .99, rope = c(-2, 2))
```

#### Significance Test

This code produces NHST for the identified comparison (using a default test value of zero).
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> testMeanDifference()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> testMeanDifference()
```

If the default value of zero is not plausible, it too can be changed.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> testMeanDifference(mu = -2)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> testMeanDifference(mu = -2)
```

#### Standardized Effect Size

This code calculates a standardized mean difference for the comparison and its confidence interval.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateStandardizedMeanDifference()
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateStandardizedMeanDifference()
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateStandardizedMeanDifference(conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> pick(A1, A2) |> estimateStandardizedMeanDifference(conf.level = .99)
```

### Analyses of a Contrast

This section produces analyses involving multiple levels of a factor.

#### Confidence Intervals

This code produces a confidence interval for that contrast.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeanContrast(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeanContrast(contrast = c(-1, .5, .5))
```

This code obtains and plots the confidence intervals for the groups and the mean difference in the identified contrast.
```{r, Factorial-Data-ContrastA}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeanContrast(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeanContrast(contrast = c(-1, .5, .5))
```

As in all other cases, the default value of the confidence interval can be changed.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
```

The width of the confidence interval for the contrast can be altered and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, Factorial-Data-ContrastB}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeanContrast(contrast = c(-1, .5, .5), conf.level = .99, line = 0, rope = c(-2, 2))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeanContrast(contrast = c(-1, .5, .5), conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the mean subsets and the mean contrast in one command.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeanSubsets(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeanSubsets(contrast = c(-1, .5, .5))
```

This code produces a difference plot using the confidence intervals for the mean subsets and the mean contrast.
```{r, Factorial-Data-SubsetsA}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeanSubsets(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeanSubsets(contrast = c(-1, .5, .5))
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateMeanSubsets(contrast = c(-1, .5, .5), conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateMeanSubsets(contrast = c(-1, .5, .5), conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, Factorial-Data-SubsetsB}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> plotMeanSubsets(contrast = c(-1, .5, .5), labels = c("Level1", "Others"), conf.level = .99, rope = c(-2, 2))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> plotMeanSubsets(contrast = c(-1, .5, .5), labels = c("Level1", "Others"), conf.level = .99, rope = c(-2, 2))
```

#### Significance Test

This code produces a NHST for the identified contrast. It tests the contrast against a value of zero by default.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> testMeanContrast(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> testMeanContrast(contrast = c(-1, .5, .5))
```

If desired, the contrast can be tested against other values.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> testMeanContrast(contrast = c(-1, .5, .5), mu = 4)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> testMeanContrast(contrast = c(-1, .5, .5), mu = 4)
```

#### Standardized Effect Size

This code calculates a standardized contrast and its confidence interval.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5))
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5))
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(FactorialDataB1) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
(FactorialDataB2) %$>% (Outcome ~ FactorA) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
```
