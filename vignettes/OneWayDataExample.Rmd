---
title: "OneWay Data Example"
output:
  github_document:
    preserve_yaml: FALSE
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 6, fig.path = "figures/", echo = TRUE, warning = FALSE, message = FALSE)
```

```{r, include=FALSE}
if (!require(EASI)) {
  if (!require(remotes)) install.packages("remotes")
  remotes::install_github("cwendorf/EASI")
}
library(EASI)
```

This page analyzes a single-factor between-subjects (one-way) design using raw data input.

## Data Management

### Data Entry

This code inputs the variable names and creates a viewable data frame.
```{r}
Factor <- c(rep(1, 10), rep(2, 10), rep(3, 10))
Factor <- factor(Factor, levels = c(1, 2, 3), labels = c("Level1", "Level2", "Level3"))
Outcome <- c(6, 8, 6, 8, 10, 8, 10, 9, 8, 7, 7, 13, 11, 10, 13, 8, 11, 14, 12, 11, 9, 16, 11, 12, 15, 13, 9, 14, 11, 10)
OneWayData <- construct(Factor, Outcome)
```

### Summary Statistics

This code obtains the descriptive statistics for the data frame.
```{r}
(Outcome ~ Factor) |> describeSummary()
```

## Analyses of the Means

This section produces analyses that are equivalent to one-sample analyses separately for each level of a factor.

### Confidence Intervals

This code will provide a table of confidence intervals for each level of the factor.
```{r}
(Outcome ~ Factor) |> estimateMeans()
```

This code will produce a graph of the confidence intervals for each level of the factor.
```{r, OneWay-Data-MeansA}
(Outcome ~ Factor) |> plotMeans()
```

The code defaults to 95% confidence intervals. This can be changed if desired.
```{r}
(Outcome ~ Factor) |> estimateMeans(conf.level = .99)
```

For the graph, it is possible to add a comparison line to represent a population (or test) value and a region of practical equivalence in addition to changing the confidence level.
```{r, OneWay-Data-MeansB}
(Outcome ~ Factor) |> plotMeans(conf.level = .99, line = 9, rope = c(8, 10))
```

### Significance Tests

This code will produce a table of NHST separately for each level of the factor. In this case, all the means are tested against a value of zero.
```{r}
(Outcome ~ Factor) |> testMeans()
```

Often, the default test value of zero is not meaningful or plausible. This too can be altered (often in conjunction with what is presented in the plot).
```{r}
(Outcome ~ Factor) |> testMeans(mu = 9)
```

### Standardized Effect Sizes

This code will produce a table of standardized mean differences separately for each level of the factor. In this case, the mean is compared to zero to form the effect size.
```{r}
(Outcome ~ Factor) |> standardizeMeans()
```

Here too it is possible to alter the width of the confidence intervals and to establish a more plausible comparison value for the mean.
```{r}
(Outcome ~ Factor) |> standardizeMeans(mu = 59, conf.level = .99)
```

## Analyses of a Comparison

This section produces analyses involving comparisons of two levels of a factor.

### Confidence Intervals

This code estimates the confidence interval of the difference.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> estimateDifference()
```

This code obtains and plots the confidence interval for the mean difference in the identified comparison.
```{r, OneWay-Data-DifferenceA}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> plotDifference()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> estimateDifference(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-DifferenceB}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> plotDifference(conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the means and the mean difference in one command.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> estimateComparison()
```

This code produces a difference plot using the confidence intervals for the means and the mean difference.
```{r, OneWay-Data-ComparisonA}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> plotComparison()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> estimateComparison(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-ComparisonB}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> plotComparison(conf.level = .99, rope = c(-2, 2))
```

### Significance Test

This code produces NHST for the identified comparison (using a default test value of zero).
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> testDifference()
```

If the default value of zero is not plausible, it too can be changed.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> testDifference(mu = -2)
```

### Standardized Effect Size

This code calculates a standardized mean difference for the comparison and its confidence interval.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> standardizeDifference()
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(Outcome ~ Factor) |> focus("Level1", "Level2") |> standardizeDifference(conf.level = .99)
```

## Analyses of a Contrast

This section produces analyses involving multiple levels of a factor.

### Confidence Intervals

This code produces a confidence interval for that contrast.
```{r}
(Outcome ~ Factor) |> estimateContrast(contrast = c(-1, .5, .5))
```

This code obtains and plots the confidence intervals for the mean difference in the identified contrast.
```{r, OneWay-Data-ContrastA}
(Outcome ~ Factor) |> plotContrast(contrast = c(-1, .5, .5))
```

As in all other cases, the default value of the confidence interval can be changed.
```{r}
(Outcome ~ Factor) |> estimateContrast(contrast = c(-1, .5, .5), conf.level = .99)
```

The width of the confidence interval for the contrast can be altered and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-ContrastB}
(Outcome ~ Factor) |> plotContrast(contrast = c(-1, .5, .5), conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the mean subsets and the mean contrast in one command.
```{r}
(Outcome ~ Factor) |> estimateSubsets(contrast = c(-1, .5, .5))
```

This code produces a difference plot using the confidence intervals for the mean subsets and the mean contrast.
```{r, OneWay-Data-SubsetsA}
(Outcome ~ Factor) |> plotSubsets(contrast = c(-1, .5, .5))
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> estimateSubsets(contrast = c(-1, .5, .5), conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-SubsetsB}
(Outcome ~ Factor) |> plotSubsets(contrast = c(-1, .5, .5), labels = c("Level1", "Others"), conf.level = .99, rope = c(-2, 2))
```

### Significance Test

This code produces a NHST for the identified contrast. It tests the contrast against a value of zero by default.
```{r}
(Outcome ~ Factor) |> testContrast(contrast = c(-1, .5, .5))
```

If desired, the contrast can be tested against other values.
```{r}
(Outcome ~ Factor) |> testContrast(contrast = c(-1, .5, .5), mu = 4)
```

### Standardized Effect Size

This code calculates a standardized contrast and its confidence interval.
```{r}
(Outcome ~ Factor) |> standardizeContrast(contrast = c(-1, .5, .5))
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(Outcome ~ Factor) |> standardizeContrast(contrast = c(-1, .5, .5), conf.level = .99)
```
