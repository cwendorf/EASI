---
subtitle: "OneWay Data Example"
output:
  github_document:
    preserve_yaml: FALSE
vignette: >
  %\VignetteIndexEntry{OneWay Data Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 6, fig.path = "figures/", echo = TRUE, warning = FALSE, message = FALSE)
devtools::source_gist("8e6e5dc401e3fc1042ef7a030f9d19c7", filename = "revised_toc.R")
```

```{r, include=FALSE}
if (!require(EASI)) {
  if (!require(remotes)) install.packages("remotes")
  remotes::install_github("cwendorf/EASI")
}
library(EASI)
```

## OneWay Data Example

This page analyzes a single-factor between-subjects (one-way) design using raw data input.

```{r toc, echo=FALSE}
thisfile <- knitr::current_input()
revised_toc(thisfile, base_level = 3, toc_depth = 4)
```

---

### Data Management

#### Data Entry

This code inputs the variable names and creates a viewable data frame.
```{r}
Factor <- c(rep(1, 10), rep(2, 10), rep(3, 10))
Factor <- factor(Factor, levels = c(1, 2, 3), labels = c("Level1", "Level2", "Level3"))
Outcome <- c(6, 8, 6, 8, 10, 8, 10, 9, 8, 7, 7, 13, 11, 10, 13, 8, 11, 14, 12, 11, 9, 16, 11, 12, 15, 13, 9, 14, 11, 10)
OneWayData <- construct(Factor, Outcome)
```

#### Summary Statistics

This code obtains the descriptive statistics for the data frame.
```{r}
(Outcome ~ Factor) |> describeSummary()
```

### Analyses of the Means

This section produces analyses that are equivalent to one-sample analyses separately for each level of a factor.

#### Confidence Intervals

This code will provide a table of confidence intervals for each level of the factor.
```{r}
(Outcome ~ Factor) |> estimateMeans()
```

This code will produce a graph of the confidence intervals for each level of the factor.
```{r, OneWay-Data-MeansA}
(Outcome ~ Factor) |> plotMeans()
```

The code defaults to 95% confidence intervals. This can be changed if desired.
```{r}
(Outcome ~ Factor) |> estimateMeans(conf.level = .99)
```

For the graph, it is possible to add a comparison line to represent a population (or test) value and a region of practical equivalence in addition to changing the confidence level.
```{r, OneWay-Data-MeansB}
(Outcome ~ Factor) |> plotMeans(conf.level = .99, line = 9, rope = c(8, 10))
```

#### Significance Tests

This code will produce a table of NHST separately for each level of the factor. In this case, all the means are tested against a value of zero.
```{r}
(Outcome ~ Factor) |> testMeans()
```

Often, the default test value of zero is not meaningful or plausible. This too can be altered (often in conjunction with what is presented in the plot).
```{r}
(Outcome ~ Factor) |> testMeans(mu = 9)
```

#### Standardized Effect Sizes

This code will produce a table of standardized mean differences separately for each level of the factor. In this case, the mean is compared to zero to form the effect size.
```{r}
(Outcome ~ Factor) |> estimateStandardizedMeans()
```

Here too it is possible to alter the width of the confidence intervals and to establish a more plausible comparison value for the mean.
```{r}
(Outcome ~ Factor) |> estimateStandardizedMeans(mu = 59, conf.level = .99)
```

### Analyses of a Comparison

This section produces analyses involving comparisons of two levels of a factor.

#### Confidence Intervals

This code estimates the confidence interval of the difference.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateMeanDifference()
```

This code obtains and plots the confidence interval for the mean difference in the identified comparison.
```{r, OneWay-Data-DifferenceA}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> plotMeanDifference()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateMeanDifference(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-DifferenceB}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> plotMeanDifference(conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the means and the mean difference in one command.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateMeanComparison()
```

This code produces a difference plot using the confidence intervals for the means and the mean difference.
```{r, OneWay-Data-ComparisonA}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> plotMeanComparison()
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateMeanComparison(conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-ComparisonB}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> plotMeanComparison(conf.level = .99, rope = c(-2, 2))
```

#### Significance Test

This code produces NHST for the identified comparison (using a default test value of zero).
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> testMeanDifference()
```

If the default value of zero is not plausible, it too can be changed.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> testMeanDifference(mu = -2)
```

#### Standardized Effect Size

This code calculates a standardized mean difference for the comparison and its confidence interval.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateStandardizedMeanDifference()
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(Outcome ~ Factor) |> pick("Level1", "Level2") |> estimateStandardizedMeanDifference(conf.level = .99)
```

### Analyses of a Contrast

This section produces analyses involving multiple levels of a factor.

#### Confidence Intervals

This code produces a confidence interval for that contrast.
```{r}
(Outcome ~ Factor) |> estimateMeanContrast(contrast = c(-1, .5, .5))
```

This code obtains and plots the confidence intervals for the mean difference in the identified contrast.
```{r, OneWay-Data-ContrastA}
(Outcome ~ Factor) |> plotMeanContrast(contrast = c(-1, .5, .5))
```

As in all other cases, the default value of the confidence interval can be changed.
```{r}
(Outcome ~ Factor) |> estimateMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
```

The width of the confidence interval for the contrast can be altered and a comparison line to represent a population (or test) value and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-ContrastB}
(Outcome ~ Factor) |> plotMeanContrast(contrast = c(-1, .5, .5), conf.level = .99, line = 0, rope = c(-2, 2))
```

If you wish, you can get the confidence intervals for the mean subsets and the mean contrast in one command.
```{r}
(Outcome ~ Factor) |> estimateMeanSubsets(contrast = c(-1, .5, .5))
```

This code produces a difference plot using the confidence intervals for the mean subsets and the mean contrast.
```{r, OneWay-Data-SubsetsA}
(Outcome ~ Factor) |> plotMeanSubsets(contrast = c(-1, .5, .5))
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
(Outcome ~ Factor) |> estimateMeanSubsets(contrast = c(-1, .5, .5), conf.level = .99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r, OneWay-Data-SubsetsB}
(Outcome ~ Factor) |> plotMeanSubsets(contrast = c(-1, .5, .5), labels = c("Level1", "Others"), conf.level = .99, rope = c(-2, 2))
```

#### Significance Test

This code produces a NHST for the identified contrast. It tests the contrast against a value of zero by default.
```{r}
(Outcome ~ Factor) |> testMeanContrast(contrast = c(-1, .5, .5))
```

If desired, the contrast can be tested against other values.
```{r}
(Outcome ~ Factor) |> testMeanContrast(contrast = c(-1, .5, .5), mu = 4)
```

#### Standardized Effect Size

This code calculates a standardized contrast and its confidence interval.
```{r}
(Outcome ~ Factor) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5))
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
(Outcome ~ Factor) |> estimateStandardizedMeanContrast(contrast = c(-1, .5, .5), conf.level = .99)
```
