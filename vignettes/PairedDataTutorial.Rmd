---
title: "Paired Samples Tutorial with Data"
author: "Craig A. Wendorf"
date: "2020-10-20"
output: 
  rmarkdown::html_vignette:
    keep_md: TRUE
vignette: >
  %\VignetteIndexEntry{Paired Samples Tutorial with Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::source_gist("c83e078bf8c81b035e32c3fc0cf04ee8",filename="render_toc.R")
```

```{r,include=FALSE}
#suppress the warnings and other messages from showing in the knitted file.
knitr::opts_chunk$set(fig.width=7, fig.height=5,fig.path='figures/',echo=TRUE,warning=FALSE,message=FALSE)
```

```{r,include=FALSE}
library(EASI)
```

## Paired Samples Tutorial with Data

### Table of Contents

```{r toc, echo=FALSE}
sourceDir <- getSrcDirectory(function(dummy) {dummy})
setwd(sourceDir)
render_toc("PairedDataTutorial.Rmd")
```

### Data Management

#### Data Entry

This code inputs the variable names and creates a viewable data frame.
```{r}
Outcome1 <- c(0,0,3,5)
Outcome2 <- c(4,7,4,9)
PairedData <- data.frame(Outcome1,Outcome2)
```

#### Plot of the Data

```{r,Paired-Violins}
plotViolins(Outcome1,Outcome2,main="Summaries of the Variables")
plotBoxes(Outcome1,Outcome2,add=TRUE)
plotData(Outcome1,Outcome2,add=TRUE,method="stack",pch=16)
```

#### Descriptive Statistics

This code obtains the descriptive statistics for the data frame.
```{r}
describeMeans(Outcome1,Outcome2)
```

### Analyses of the Means

This section produces analyses that are equivalent to one-sample analyses separately for each level of a factor.

#### Confidence Intervals for the Means

This code will provide a table of confidence intervals for each level of the factor.
```{r}
estimateMeans(Outcome1,Outcome2)
```

This code will produce a graph of the confidence intervals for each level of the factor.
```{r,Paired-MeansA}
plotMeans(Outcome1,Outcome2)
```

The code defaults to 95% confidence intervals. This can be changed if desired.
```{r}
estimateMeans(Outcome1,Outcome2,conf.level=.99)
```

For the graph, it is possible to add a comparison line to represent a population (or test) value and a region of practical equivalence in addition to changing the confidence level.
```{r,Paired-MeansB}
plotMeans(Outcome1,Outcome2,conf.level=.99,mu=6,rope=c(4,8))
```

#### Significance Tests for the Means

This code will produce a table of NHST separately for each level of the factor. In this case, all the means are tested against a value of zero.
```{r}
testMeans(Outcome1,Outcome2)
```

Often, the default test value of zero is not meaningful or plausible. This too can be altered (often in conjunction with what is presented in the plot).
```{r}
testMeans(Outcome1,Outcome2,mu=6)
```

#### Standardized Effect Sizes for the Means

This code will produce a table of standardized mean differences separately for each level of the factor. In this case, the mean is compared to zero to form the effect size.
```{r}
estimateStandardizedMeans(Outcome1,Outcome2)
```

Here too it is possible to alter the width of the confidence intervals and to establish a more plausible comparison value for the mean.
```{r}
estimateStandardizedMeans(Outcome1,Outcome2,mu=6,conf.level=.99)
```

### Analyses of the Comparison

This section produces analyses that examine the difference among the two levels of the factor.

#### Confidence Interval for the Mean Difference

This code estimates the confidence interval of the difference.
```{r}
estimateMeanDifference(Outcome1,Outcome2)
```

This code obtains and plots the confidence intervals for the mean difference.
```{r,Paired-DifferenceA}
plotMeanDifference(Outcome1,Outcome2)
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
estimateMeanDifference(Outcome1,Outcome2,conf.level=.99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r,Paired-DifferenceB}
plotMeanDifference(Outcome1,Outcome2,conf.level=.99,rope=c(-2,2))
```

#### Confidence Intervals for the Comparison

If you wish, you can get the confidence intervals for the means and the mean difference in one command.
```{r}
estimateMeanComparison(Outcome1,Outcome2)
```

This code produces a difference plot using the confidence intervals for the means and the mean difference.
```{r,Paired-ComparisonA}
plotMeanComparison(Outcome1,Outcome2)
```

Of course, you can change the confidence level from the default 95% if desired.
```{r}
estimateMeanComparison(Outcome1,Outcome2,conf.level=.99)
```

Once again, the confidence levels can be changed away from the default and a region of practical equivalence can be added to the graph.
```{r,Paired-ComparisonB}
plotMeanComparison(Outcome1,Outcome2,conf.level=.99,rope=c(-2,2))
```

#### Significance Test for the Mean Difference

This code produces NHST for the mean difference (using a default test value of zero).
```{r}
testMeanDifference(Outcome1,Outcome2)
```

If the default value of zero is not plausible, it too can be changed.
```{r}
testMeanDifference(Outcome1,Outcome2,mu=-2)
```

#### Standardized Effect Size for the Mean Difference

This code calculates a standardized mean difference and its confidence interval.
```{r}
estimateStandardizedMeanDifference(Outcome1,Outcome2)
```

The width of the confidence interval for the effect size can be altered if desired.
```{r}
estimateStandardizedMeanDifference(Outcome1,Outcome2,conf.level=.99)
```
